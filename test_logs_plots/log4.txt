EfficientNetB0


C:\Users\canse\AppData\Local\Programs\Python\Python312\python.exe C:\Users\canse\Desktop\project\codepart23.py 
2025-01-20 18:15:06.233171: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-01-20 18:15:07.990382: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
Found 1933 images belonging to 20 classes.
Found 477 images belonging to 20 classes.
2025-01-20 18:15:13.427570: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5
16705208/16705208 ━━━━━━━━━━━━━━━━━━━━ 3s 0us/step
C:\Users\canse\AppData\Local\Programs\Python\Python312\Lib\site-packages\keras\src\trainers\data_adapters\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.
  self._warn_if_super_not_called()
Epoch 1/25
61/61 ━━━━━━━━━━━━━━━━━━━━ 54s 740ms/step - accuracy: 0.5865 - loss: 2.2028 - val_accuracy: 0.9057 - val_loss: 0.4294
Epoch 2/25
61/61 ━━━━━━━━━━━━━━━━━━━━ 45s 742ms/step - accuracy: 0.8600 - loss: 0.6466 - val_accuracy: 0.9099 - val_loss: 0.3936
Epoch 3/25
61/61 ━━━━━━━━━━━━━━━━━━━━ 43s 709ms/step - accuracy: 0.8936 - loss: 0.5641 - val_accuracy: 0.9245 - val_loss: 0.3081
Epoch 4/25
61/61 ━━━━━━━━━━━━━━━━━━━━ 44s 729ms/step - accuracy: 0.8925 - loss: 0.4052 - val_accuracy: 0.9203 - val_loss: 0.3636
Epoch 5/25
61/61 ━━━━━━━━━━━━━━━━━━━━ 43s 707ms/step - accuracy: 0.9025 - loss: 0.4393 - val_accuracy: 0.9455 - val_loss: 0.2707
Epoch 6/25
61/61 ━━━━━━━━━━━━━━━━━━━━ 44s 726ms/step - accuracy: 0.9229 - loss: 0.3119 - val_accuracy: 0.9392 - val_loss: 0.3614
Epoch 7/25
61/61 ━━━━━━━━━━━━━━━━━━━━ 44s 718ms/step - accuracy: 0.9293 - loss: 0.3629 - val_accuracy: 0.9266 - val_loss: 0.3347
Epoch 8/25
61/61 ━━━━━━━━━━━━━━━━━━━━ 44s 719ms/step - accuracy: 0.9163 - loss: 0.3726 - val_accuracy: 0.9539 - val_loss: 0.2442
Epoch 9/25
61/61 ━━━━━━━━━━━━━━━━━━━━ 47s 766ms/step - accuracy: 0.9403 - loss: 0.2694 - val_accuracy: 0.9518 - val_loss: 0.2568
Epoch 10/25
61/61 ━━━━━━━━━━━━━━━━━━━━ 44s 728ms/step - accuracy: 0.9339 - loss: 0.2979 - val_accuracy: 0.9476 - val_loss: 0.2474
Epoch 11/25
61/61 ━━━━━━━━━━━━━━━━━━━━ 47s 773ms/step - accuracy: 0.9430 - loss: 0.2643 - val_accuracy: 0.9518 - val_loss: 0.3297
Epoch 12/25
61/61 ━━━━━━━━━━━━━━━━━━━━ 49s 801ms/step - accuracy: 0.9313 - loss: 0.3395 - val_accuracy: 0.9560 - val_loss: 0.2994
Epoch 13/25
61/61 ━━━━━━━━━━━━━━━━━━━━ 47s 767ms/step - accuracy: 0.9515 - loss: 0.2899 - val_accuracy: 0.9308 - val_loss: 0.3167
Epoch 14/25
61/61 ━━━━━━━━━━━━━━━━━━━━ 45s 743ms/step - accuracy: 0.9505 - loss: 0.2275 - val_accuracy: 0.9392 - val_loss: 0.3243
Epoch 15/25
61/61 ━━━━━━━━━━━━━━━━━━━━ 42s 680ms/step - accuracy: 0.9487 - loss: 0.1761 - val_accuracy: 0.9623 - val_loss: 0.2885
Epoch 16/25
61/61 ━━━━━━━━━━━━━━━━━━━━ 41s 670ms/step - accuracy: 0.9499 - loss: 0.2762 - val_accuracy: 0.9518 - val_loss: 0.3025
Epoch 17/25
61/61 ━━━━━━━━━━━━━━━━━━━━ 43s 714ms/step - accuracy: 0.9423 - loss: 0.3029 - val_accuracy: 0.9518 - val_loss: 0.3065
Epoch 18/25
61/61 ━━━━━━━━━━━━━━━━━━━━ 41s 665ms/step - accuracy: 0.9423 - loss: 0.3454 - val_accuracy: 0.9371 - val_loss: 0.4838
Epoch 19/25
61/61 ━━━━━━━━━━━━━━━━━━━━ 44s 721ms/step - accuracy: 0.9336 - loss: 0.3037 - val_accuracy: 0.9476 - val_loss: 0.3890
Epoch 20/25
61/61 ━━━━━━━━━━━━━━━━━━━━ 42s 693ms/step - accuracy: 0.9550 - loss: 0.2582 - val_accuracy: 0.9581 - val_loss: 0.3550
Epoch 21/25
61/61 ━━━━━━━━━━━━━━━━━━━━ 43s 711ms/step - accuracy: 0.9667 - loss: 0.1609 - val_accuracy: 0.9497 - val_loss: 0.4121
Epoch 22/25
61/61 ━━━━━━━━━━━━━━━━━━━━ 41s 685ms/step - accuracy: 0.9468 - loss: 0.2435 - val_accuracy: 0.9560 - val_loss: 0.3676
Epoch 23/25
61/61 ━━━━━━━━━━━━━━━━━━━━ 41s 673ms/step - accuracy: 0.9487 - loss: 0.2464 - val_accuracy: 0.9497 - val_loss: 0.3861
Epoch 24/25
61/61 ━━━━━━━━━━━━━━━━━━━━ 41s 672ms/step - accuracy: 0.9556 - loss: 0.1958 - val_accuracy: 0.9497 - val_loss: 0.5017
Epoch 25/25
61/61 ━━━━━━━━━━━━━━━━━━━━ 44s 718ms/step - accuracy: 0.9610 - loss: 0.2252 - val_accuracy: 0.9602 - val_loss: 0.3093
1/1 ━━━━━━━━━━━━━━━━━━━━ 3s 3s/step
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 418ms/step
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 462ms/step
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 478ms/step
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 448ms/step
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 495ms/step
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 500ms/step
1/1 ━━━━━━━━━━━━━━━━━━━━ 1s 500ms/step
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 464ms/step
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 457ms/step
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 465ms/step
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 450ms/step
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 436ms/step
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 487ms/step
1/1 ━━━━━━━━━━━━━━━━━━━━ 3s 3s/step

Overall Accuracy: 0.9581

Overall Metrics:
True Positives: 457
False Positives: 20
True Negatives: 9043
False Negatives: 20

Metrics for each class:

Class 0:
Precision: 0.9524
Recall: 1.0000
F1-score: 0.9756

Class 1:
Precision: 0.9118
Recall: 0.9688
F1-score: 0.9394

Class 2:
Precision: 0.9474
Recall: 0.9000
F1-score: 0.9231

Class 3:
Precision: 0.9444
Recall: 0.8500
F1-score: 0.8947

Class 4:
Precision: 1.0000
Recall: 1.0000
F1-score: 1.0000

Class 5:
Precision: 0.9744
Recall: 0.9870
F1-score: 0.9806

Class 6:
Precision: 1.0000
Recall: 0.8500
F1-score: 0.9189

Class 7:
Precision: 0.9524
Recall: 1.0000
F1-score: 0.9756

Class 8:
Precision: 1.0000
Recall: 1.0000
F1-score: 1.0000

Class 9:
Precision: 1.0000
Recall: 1.0000
F1-score: 1.0000

Class 10:
Precision: 1.0000
Recall: 0.9500
F1-score: 0.9744

Class 11:
Precision: 1.0000
Recall: 1.0000
F1-score: 1.0000

Class 12:
Precision: 1.0000
Recall: 0.9500
F1-score: 0.9744

Class 13:
Precision: 1.0000
Recall: 1.0000
F1-score: 1.0000

Class 14:
Precision: 0.7692
Recall: 1.0000
F1-score: 0.8696

Class 15:
Precision: 0.9565
Recall: 0.9565
F1-score: 0.9565

Class 16:
Precision: 0.8696
Recall: 1.0000
F1-score: 0.9302

Class 17:
Precision: 0.9412
Recall: 0.8000
F1-score: 0.8649

Class 18:
Precision: 1.0000
Recall: 1.0000
F1-score: 1.0000

Class 19:
Precision: 1.0000
Recall: 0.8500
F1-score: 0.9189

Weighted Average Metrics:
Precision: 0.9617
Recall: 0.9581
F1-score: 0.9580

Detailed Classification Report:
              precision    recall  f1-score   support

           0       0.95      1.00      0.98        20
           1       0.91      0.97      0.94        32
           2       0.95      0.90      0.92        20
           3       0.94      0.85      0.89        20
           4       1.00      1.00      1.00        20
           5       0.97      0.99      0.98        77
           6       1.00      0.85      0.92        20
           7       0.95      1.00      0.98        20
           8       1.00      1.00      1.00        20
           9       1.00      1.00      1.00        20
          10       1.00      0.95      0.97        20
          11       1.00      1.00      1.00        20
          12       1.00      0.95      0.97        20
          13       1.00      1.00      1.00        23
          14       0.77      1.00      0.87        20
          15       0.96      0.96      0.96        23
          16       0.87      1.00      0.93        20
          17       0.94      0.80      0.86        20
          18       1.00      1.00      1.00        22
          19       1.00      0.85      0.92        20

    accuracy                           0.96       477
   macro avg       0.96      0.95      0.95       477
weighted avg       0.96      0.96      0.96       477


Process finished with exit code 0
